---
title: "wordList"
author: "Luyang Fang"
date: "2020/11/25"
output: html_document
---

```{r include=FALSE}
rm(list=ls())
library(dplyr)
library(tidytext)
library(tidyr)
library(ggplot2)
library(reshape2)
library(wordcloud)
```

## read data

```{r}
review = read.csv("../clean_data/Chinese/review_Chinese.csv")
business = read.csv("../clean_data/Chinese/business_Chinese.csv")
```


## tranfer into token

```{r}
text_df <- tibble(review[,c(1,3,4,8)])
tidy_text = text_df %>% unnest_tokens(word,text) # tokenization
tidy_text = anti_join(tidy_text,stop_words) # remove stop words
```


### count

```{r}
count = tidy_text %>%
  count(word, sort = TRUE) %>%
  mutate(word=reorder(word, n)) # 33504
head(count,20)
## plot first 20
count %>% 
  head(20) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)
# write.csv(count,"wordList_original.csv",row.names=F)
```


### word cloud
```{r}
count %>% 
  with(wordcloud(word, n, max.words = 100))
```

## decide wordList

```{r}
# according to colnames in business.csv
name = colnames(business)
name_new = gsub("attribute.","",name)[12:51]
try = c("attire","takeout","credit","noise","kid","reservation","groups","parking","price","tv","alcohol","bike","delivery","appointment","outdoor","wifi","wheel","ambience","byob","music","dog","dance","age","smoking","smoke","service")
sum(try %in% count$word) # 25
count[count$word %in% try,]
```

```{r}
# according to word frenquency
list = count[count$n>500,] # 473 
# write.csv(list,"freq500.csv",row.names=FALSE)
sum(try %in% list$word) # 5 
list %>% 
  with(wordcloud(word, n, max.words = 100))

```

```{r}
# delete some words may not be useful for our analysis
list_2 = list[-c(2,4,24,27,34,35,46,48,53,56,58,59,61,62,68,76,78,79,87,90,98,101,102,103,113,115,117,127,130,131,136,137,138,140,142,146,148,149,152,156,158,159,160,161,163,164,167,170,171,172,174,177,178,179,180,183,185,187,189,190,192,193,195,198,199,202,203,204,205,206,211,213,216,218,222,223,224,225,227,228,229,230,231,232,234,235,236,241,243,244,246,247,251,254,255,256,257,258,260,261,262,263,265,268,269,270,271,273,274,275,277,279,280,281,282,285,288,289,291,298,301,303,304,306,310,311,314,316,317,319,321,322,324,326,332,334,335,337,341,345,347,349,353,354,355,357,359,362,365,366,368,370,371,373,378,383,384,387,388,389,390,393,394,396,399,400,404,406,410,413,415,420,422,424,425,428,429,430,431,439,441,443,444,446,447,449,464,468,470,471,473),]
list_2 = list_2[-c(15,17,21,45,5058,60,70,73,74,79,83,101,193,201,203,204,208,217,219,226,248,281),]
#write.csv(list_2,"wordList_V2.csv",row.names=F)

list_2 %>% 
  with(wordcloud(word, n, max.words = 100))
```



## filter
```{r}
review_num = business$review_count
hist(review_num,breaks=50,
     xlab="Review number",main="Histogram of review number")
hist(review_num[review_num<50],breaks=10,
     xlab="Review number",main="Histogram of review number")
quantile(review_num)
# 50%(?) (# of review>22)
business_filter = business[review_num>quantile(review_num)[3],]
write.csv(business_filter,"../clean_data/Chinese/business_filter.csv",row.names=F)
```


## foodList
```{r}
# list of food people talk a lot, 
# maybe business should pay attention to those food
foodList = list_2[c(2,5,6,11,13,17,19,20,22,39,41,43),]
# write.csv(foodList,"foodList_12.csv",row.names=F)
```

